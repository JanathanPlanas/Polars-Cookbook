{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Reading and Writing Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/customer_shopping_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/customer_shopping_data_no_header.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/customer_shopping_data_no_header.csv', has_header=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['invoice_no', 'customer_id', 'gender', 'age', 'category', 'quantity', 'price', 'payment_method', 'invoice_date', 'shopping_mall']\n",
    "df = pl.read_csv('../data/customer_shopping_data_no_header.csv', \n",
    "                 has_header=False, \n",
    "                 new_columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/customer_shopping_data_no_header.csv', \n",
    "                 has_header=False, \n",
    "                 new_columns=column_names, \n",
    "                 try_parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/customer_shopping_data_no_header.csv', \n",
    "                 has_header=False, \n",
    "                 new_columns=column_names, \n",
    "                 try_parse_dates=True, \n",
    "                 dtypes={'age': pl.Int8, 'quantity': pl.Int32})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_csv('../data/output/shopping_data_output.csv', \n",
    "             has_header=False, \n",
    "             separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_csv('../data/customer_shopping_data_no_header.csv', \n",
    "                 has_header=False, \n",
    "                 new_columns=column_names, \n",
    "                 try_parse_dates=True, \n",
    "                 dtypes={'age': pl.Int8, 'quantity': pl.Int32})\n",
    "lf.fetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.sink_csv('../data/output/shopping_data_output_sink.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_input_file_path = '../data/venture_funding_deals.parquet'\n",
    "df = pl.read_parquet(parquet_input_file_path, \n",
    "                     columns=['Company', 'Amount', 'Valuation', 'Industry'], \n",
    "                     row_count_name='row_cnt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_parquet_schema(parquet_input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_output_file_path = '../data/output/venture_funding_deals_output.parquet'\n",
    "df.write_parquet(parquet_output_file_path, compression='zstd', compression_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_parquet(parquet_input_file_path)\n",
    "lf.collect().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.sink_parquet(parquet_output_file_path, maintain_order=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_parquet_input_file_path = '../data/venture_funding_deals_partitioned'\n",
    "df = pl.read_parquet(\n",
    "    partitioned_parquet_input_file_path, \n",
    "    use_pyarrow=True, \n",
    "    pyarrow_options={'partitioning': 'hive'}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_parquet_output_file_path = '../data/output/venture_funding_deals_partitioned_output'\n",
    "df.write_parquet(\n",
    "    partitioned_parquet_output_file_path, \n",
    "    use_pyarrow=True, \n",
    "    pyarrow_options={\n",
    "        'partition_cols': ['Industry'],\n",
    "        'existing_data_behavior': 'overwrite_or_ignore'\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing Delta Lake tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_input_file_path = '../data/venture_funding_deals_delta'\n",
    "df = pl.read_delta(delta_input_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_delta(delta_input_file_path)\n",
    "lf.collect().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_delta('../data/output/venture_funding_deals_delta_output', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_partitioned_output_file_path = '../data/output/venture_funding_deals_delta_partitioned_output'\n",
    "delta_write_options = {'partition_by': 'Industry'}\n",
    "df.write_delta(\n",
    "    delta_partitioned_output_file_path, \n",
    "    mode='overwrite', \n",
    "    delta_write_options=delta_write_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_delta(delta_partitioned_output_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_delta(\n",
    "    delta_partitioned_output_file_path, \n",
    "    pyarrow_options={'partitions': [('Industry', '=', 'Accounting')]}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import aws_access_key_id, aws_secret_access_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = 's3://sandbox-data-lake/letters_delta'\n",
    "storage_options= {\n",
    "    'aws_access_key_id': aws_access_key_id,\n",
    "    'aws_secret_access_key': aws_secret_access_key,\n",
    "    'aws_region': 'us-west-1'\n",
    "}\n",
    "\n",
    "table_path = 's3://YOUR_S3BUCKET_URI/YOUR_DELTA_TABLE'\n",
    "storage_options= {\n",
    "    'aws_access_key_id': 'YOUR_ACCESS_KEY',\n",
    "    'aws_secret_access_key': 'YOUR_SECRET_ACCESS_KEY',\n",
    "    'aws_region': 'YOUR_REGION'\n",
    "}\n",
    "\n",
    "df = pl.read_delta(table_path, storage_options=storage_options)  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_json('../data/world_population.json')\n",
    "df.select(df.columns[:10]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_json('../data/output/world_population_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_ndjson('../data/world_population.jsonl')\n",
    "df.select(df.columns[:10]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_ndjson('../data/output/world_population_output.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_ndjson('../data/world_population.jsonl')\n",
    "lf.select(lf.columns[:10]).collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing Excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '../data/financial_sample.xlsx'\n",
    "df = pl.read_excel(\n",
    "    input_file_path, \n",
    "    sheet_name='Sheet1',\n",
    "    read_csv_options={'has_header': True, 'try_parse_dates': True}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = '../data/output/financial_sample_output.xlsx'\n",
    "df.write_excel(\n",
    "    output_file_path,\n",
    "    worksheet='Output Sheet1',\n",
    "    header_format={'bold': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing other file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_input_file_path = '../data/customer_shopping_data.csv'\n",
    "ipc_file_path = '../data/customer_shopping_data.arrow'\n",
    "df = pl.read_csv(csv_input_file_path)\n",
    "df.write_ipc(ipc_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_ipc(ipc_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avro_file_path = '../data/customer_shopping_data.avro'\n",
    "df = pl.read_csv(csv_input_file_path)\n",
    "df.write_avro(avro_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_avro(avro_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "duckdb.sql('INSTALL iceberg;')\n",
    "duckdb.sql('LOAD iceberg;')\n",
    "# duckdb.sql('SELECT count(*) FROM iceberg_scan(\"../data/lineitem_iceberg\", allow_moved_paths = true);')\n",
    "duckdb.sql('SELECT * FROM iceberg_scan(\"../data/lineitem_iceberg\", allow_moved_paths = true) limit 10;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iceberg_input_file_path = '../data/iceberg_table/metadata/00001-41687cbb-3a0c-4ef3-b3fa-e7026ed2eb77.metadata.json'\n",
    "# iceberg_input_file_path = '../data/iceberg_table/data/bvwNRQ/category=food/id_bucket=4/20231021_214808_00048_4bpqv-471f34de-a5e9-47a9-b2c6-c22c2a385ad8.parquet'\n",
    "iceberg_input_file_path = '../data/lineitem_iceberg/metadata/v1.metadata.json'\n",
    "lf = pl.scan_iceberg(iceberg_input_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iceberg_input_file_path = 's3://sandbox-data-lake/iceberg-folder/metadata/00001-41687cbb-3a0c-4ef3-b3fa-e7026ed2eb77.metadata.json'\n",
    "storage_options= {\n",
    "    'aws_access_key_id': aws_access_key_id,\n",
    "    'aws_secret_access_key': aws_secret_access_key,\n",
    "    'aws_region': 'us-west-1'\n",
    "}\n",
    "\n",
    "lf = pl.scan_iceberg(iceberg_input_file_path, storage_options=storage_options)  \n",
    "lf.collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>invoice_no</th><th>customer_id</th><th>gender</th><th>age</th><th>category</th><th>quantity</th><th>price</th><th>payment_method</th><th>invoice_date</th><th>shopping_mall</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;I138884&quot;</td><td>&quot;C241288&quot;</td><td>&quot;Female&quot;</td><td>28</td><td>&quot;Clothing&quot;</td><td>5</td><td>1500.4</td><td>&quot;Credit Card&quot;</td><td>&quot;5/8/2022&quot;</td><td>&quot;Kanyon&quot;</td></tr><tr><td>&quot;I317333&quot;</td><td>&quot;C111565&quot;</td><td>&quot;Male&quot;</td><td>21</td><td>&quot;Shoes&quot;</td><td>3</td><td>1800.51</td><td>&quot;Debit Card&quot;</td><td>&quot;12/12/2021&quot;</td><td>&quot;Forum Istanbul…</td></tr><tr><td>&quot;I127801&quot;</td><td>&quot;C266599&quot;</td><td>&quot;Male&quot;</td><td>20</td><td>&quot;Clothing&quot;</td><td>1</td><td>300.08</td><td>&quot;Cash&quot;</td><td>&quot;9/11/2021&quot;</td><td>&quot;Metrocity&quot;</td></tr><tr><td>&quot;I173702&quot;</td><td>&quot;C988172&quot;</td><td>&quot;Female&quot;</td><td>66</td><td>&quot;Shoes&quot;</td><td>5</td><td>3000.85</td><td>&quot;Credit Card&quot;</td><td>&quot;16/05/2021&quot;</td><td>&quot;Metropol AVM&quot;</td></tr><tr><td>&quot;I337046&quot;</td><td>&quot;C189076&quot;</td><td>&quot;Female&quot;</td><td>53</td><td>&quot;Books&quot;</td><td>4</td><td>60.6</td><td>&quot;Cash&quot;</td><td>&quot;24/10/2021&quot;</td><td>&quot;Kanyon&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌────────────┬─────────────┬────────┬─────┬───┬─────────┬──────────────┬─────────────┬─────────────┐\n",
       "│ invoice_no ┆ customer_id ┆ gender ┆ age ┆ … ┆ price   ┆ payment_meth ┆ invoice_dat ┆ shopping_ma │\n",
       "│ ---        ┆ ---         ┆ ---    ┆ --- ┆   ┆ ---     ┆ od           ┆ e           ┆ ll          │\n",
       "│ str        ┆ str         ┆ str    ┆ i64 ┆   ┆ f64     ┆ ---          ┆ ---         ┆ ---         │\n",
       "│            ┆             ┆        ┆     ┆   ┆         ┆ str          ┆ str         ┆ str         │\n",
       "╞════════════╪═════════════╪════════╪═════╪═══╪═════════╪══════════════╪═════════════╪═════════════╡\n",
       "│ I138884    ┆ C241288     ┆ Female ┆ 28  ┆ … ┆ 1500.4  ┆ Credit Card  ┆ 5/8/2022    ┆ Kanyon      │\n",
       "│ I317333    ┆ C111565     ┆ Male   ┆ 21  ┆ … ┆ 1800.51 ┆ Debit Card   ┆ 12/12/2021  ┆ Forum       │\n",
       "│            ┆             ┆        ┆     ┆   ┆         ┆              ┆             ┆ Istanbul    │\n",
       "│ I127801    ┆ C266599     ┆ Male   ┆ 20  ┆ … ┆ 300.08  ┆ Cash         ┆ 9/11/2021   ┆ Metrocity   │\n",
       "│ I173702    ┆ C988172     ┆ Female ┆ 66  ┆ … ┆ 3000.85 ┆ Credit Card  ┆ 16/05/2021  ┆ Metropol    │\n",
       "│            ┆             ┆        ┆     ┆   ┆         ┆              ┆             ┆ AVM         │\n",
       "│ I337046    ┆ C189076     ┆ Female ┆ 53  ┆ … ┆ 60.6    ┆ Cash         ┆ 24/10/2021  ┆ Kanyon      │\n",
       "└────────────┴─────────────┴────────┴─────┴───┴─────────┴──────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = pl.scan_ipc(ipc_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperationError",
     "evalue": "sink_Ipc(IpcWriterOptions { compression: Some(ZSTD), maintain_order: true }) not yet supported in standard engine. Use 'collect().write_parquet()'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperationError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/Yuki/Desktop/Polars-Cookbook/Chapter02/ch02.ipynb Cell 67\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Yuki/Desktop/Polars-Cookbook/Chapter02/ch02.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lf\u001b[39m.\u001b[39;49msink_ipc(\u001b[39m'\u001b[39;49m\u001b[39m../data/output/customer_shopping_data.arrow\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/polars/lazyframe/frame.py:2101\u001b[0m, in \u001b[0;36mLazyFrame.sink_ipc\u001b[0;34m(self, path, compression, maintain_order, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, no_optimization)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[39mEvaluate the query in streaming mode and write to an IPC file.\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \n\u001b[1;32m   2091\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2092\u001b[0m lf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_sink_optimizations(\n\u001b[1;32m   2093\u001b[0m     type_coercion\u001b[39m=\u001b[39mtype_coercion,\n\u001b[1;32m   2094\u001b[0m     predicate_pushdown\u001b[39m=\u001b[39mpredicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     no_optimization\u001b[39m=\u001b[39mno_optimization,\n\u001b[1;32m   2099\u001b[0m )\n\u001b[0;32m-> 2101\u001b[0m \u001b[39mreturn\u001b[39;00m lf\u001b[39m.\u001b[39;49msink_ipc(\n\u001b[1;32m   2102\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2103\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2104\u001b[0m     maintain_order\u001b[39m=\u001b[39;49mmaintain_order,\n\u001b[1;32m   2105\u001b[0m )\n",
      "\u001b[0;31mInvalidOperationError\u001b[0m: sink_Ipc(IpcWriterOptions { compression: Some(ZSTD), maintain_order: true }) not yet supported in standard engine. Use 'collect().write_parquet()'"
     ]
    }
   ],
   "source": [
    "lf.sink_ipc('../data/output/customer_shopping_data.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.collect().write_ipc('../data/output/customer_shopping_data.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_csv(csv_input_file_path)\n",
    "lf.sink_ipc('../data/output/customer_shopping_data_from_csv.arrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Letter': ['A','B','C'], 'Value': [1,2,3]}\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.group_by('Letter')\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs:\n",
    "    df.write_csv(f'../data/output/letter_{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/output/letter_*.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_csv('../data/output/letter_*.csv')\n",
    "lf.collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "lfs = [pl.scan_csv(file) for file in glob.glob('../data/output/letter_*.csv')]\n",
    "dfs = pl.collect_all(lfs)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import postgres_pass, postgres_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>brand</th><th>model</th><th>year</th></tr><tr><td>str</td><td>str</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Volvo&quot;</td><td>&quot;p1800&quot;</td><td>1968</td></tr><tr><td>&quot;BMW&quot;</td><td>&quot;M1&quot;</td><td>1978</td></tr><tr><td>&quot;Toyota&quot;</td><td>&quot;Celica&quot;</td><td>1975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬────────┬──────┐\n",
       "│ brand  ┆ model  ┆ year │\n",
       "│ ---    ┆ ---    ┆ ---  │\n",
       "│ str    ┆ str    ┆ i32  │\n",
       "╞════════╪════════╪══════╡\n",
       "│ Volvo  ┆ p1800  ┆ 1968 │\n",
       "│ BMW    ┆ M1     ┆ 1978 │\n",
       "│ Toyota ┆ Celica ┆ 1975 │\n",
       "└────────┴────────┴──────┘"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connectorx is required\n",
    "uri = f'postgres://{postgres_user}:{postgres_pass}@localhost:5432/postgres' \n",
    "query = 'SELECT * FROM sandbox.cars'\n",
    "df = pl.read_database_uri(query, uri)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>brand</th><th>model</th><th>year</th></tr><tr><td>str</td><td>str</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Volvo&quot;</td><td>&quot;p1800&quot;</td><td>1968</td></tr><tr><td>&quot;BMW&quot;</td><td>&quot;M1&quot;</td><td>1978</td></tr><tr><td>&quot;Toyota&quot;</td><td>&quot;Celica&quot;</td><td>1975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬────────┬──────┐\n",
       "│ brand  ┆ model  ┆ year │\n",
       "│ ---    ┆ ---    ┆ ---  │\n",
       "│ str    ┆ str    ┆ i32  │\n",
       "╞════════╪════════╪══════╡\n",
       "│ Volvo  ┆ p1800  ┆ 1968 │\n",
       "│ BMW    ┆ M1     ┆ 1978 │\n",
       "│ Toyota ┆ Celica ┆ 1975 │\n",
       "└────────┴────────┴──────┘"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install adbc-driver-postgresql pyarrow\n",
    "df = pl.read_database_uri(query, uri, engine='adbc')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/yz8bs9_14yj6_1v4hn7dh70h0000gn/T/ipykernel_59670/602348150.py:1: DeprecationWarning: Use of a string URI with 'read_database' is deprecated; use `read_database_uri` instead\n",
      "  df = pl.read_database(query, connection=uri)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>brand</th><th>model</th><th>year</th></tr><tr><td>str</td><td>str</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Volvo&quot;</td><td>&quot;p1800&quot;</td><td>1968</td></tr><tr><td>&quot;BMW&quot;</td><td>&quot;M1&quot;</td><td>1978</td></tr><tr><td>&quot;Toyota&quot;</td><td>&quot;Celica&quot;</td><td>1975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬────────┬──────┐\n",
       "│ brand  ┆ model  ┆ year │\n",
       "│ ---    ┆ ---    ┆ ---  │\n",
       "│ str    ┆ str    ┆ i32  │\n",
       "╞════════╪════════╪══════╡\n",
       "│ Volvo  ┆ p1800  ┆ 1968 │\n",
       "│ BMW    ┆ M1     ┆ 1978 │\n",
       "│ Toyota ┆ Celica ┆ 1975 │\n",
       "└────────┴────────┴──────┘"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_database(query, connection=uri)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>brand</th><th>model</th><th>year</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Volvo&quot;</td><td>&quot;p1800&quot;</td><td>1968</td></tr><tr><td>&quot;BMW&quot;</td><td>&quot;M1&quot;</td><td>1978</td></tr><tr><td>&quot;Toyota&quot;</td><td>&quot;Celica&quot;</td><td>1975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬────────┬──────┐\n",
       "│ brand  ┆ model  ┆ year │\n",
       "│ ---    ┆ ---    ┆ ---  │\n",
       "│ str    ┆ str    ┆ i64  │\n",
       "╞════════╪════════╪══════╡\n",
       "│ Volvo  ┆ p1800  ┆ 1968 │\n",
       "│ BMW    ┆ M1     ┆ 1978 │\n",
       "│ Toyota ┆ Celica ┆ 1975 │\n",
       "└────────┴────────┴──────┘"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install sqlalchemy pg8000 or psycopg2 (default is psycopg2)\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "con_string = f'postgresql+pg8000://{postgres_user}:{postgres_pass}@localhost:5432/postgres' \n",
    "engine = create_engine(con_string)\n",
    "conn = engine.connect()\n",
    "\n",
    "df = pl.read_database(query, connection=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "INVALID_ARGUMENT: [libpq] Failed to create table: ERROR:  relation \"sandbox.cars_output\" already exists\n\nQuery was: CREATE TABLE \"public\" . \"sandbox.cars_output\" (\"brand\" TEXT, \"model\" TEXT, \"year\" BIGINT). SQLSTATE: 42P07",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/Yuki/Desktop/Polars-Cookbook/Chapter02/ch02.ipynb Cell 87\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Yuki/Desktop/Polars-Cookbook/Chapter02/ch02.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mwrite_database(table_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msandbox.cars_output\u001b[39;49m\u001b[39m\"\u001b[39;49m, connection\u001b[39m=\u001b[39;49muri, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39madbc\u001b[39;49m\u001b[39m\"\u001b[39;49m, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/polars/utils/deprecation.py:100\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     97\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     98\u001b[0m         old_name, new_name, kwargs, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, version\n\u001b[1;32m     99\u001b[0m     )\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/polars/dataframe/frame.py:3469\u001b[0m, in \u001b[0;36mDataFrame.write_database\u001b[0;34m(self, table_name, connection, if_exists, engine)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3465\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munexpected value for `if_exists`: \u001b[39m\u001b[39m{\u001b[39;00mif_exists\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3466\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mChoose one of \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3467\u001b[0m         )\n\u001b[1;32m   3468\u001b[0m     \u001b[39mwith\u001b[39;00m _open_adbc_connection(connection) \u001b[39mas\u001b[39;00m conn, conn\u001b[39m.\u001b[39mcursor() \u001b[39mas\u001b[39;00m cursor:\n\u001b[0;32m-> 3469\u001b[0m         cursor\u001b[39m.\u001b[39;49madbc_ingest(table_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_arrow(), mode)\n\u001b[1;32m   3470\u001b[0m         conn\u001b[39m.\u001b[39mcommit()\n\u001b[1;32m   3472\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msqlalchemy\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/adbc_driver_manager/dbapi.py:895\u001b[0m, in \u001b[0;36mCursor.adbc_ingest\u001b[0;34m(self, table_name, data, mode, catalog_name, db_schema_name, temporary)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stmt\u001b[39m.\u001b[39mbind_stream(handle)\n\u001b[1;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_query \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stmt\u001b[39m.\u001b[39;49mexecute_update()\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/adbc_driver_manager/_lib.pyx:1184\u001b[0m, in \u001b[0;36madbc_driver_manager._lib.AdbcStatement.execute_update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Polars-Cookbook/.venv/lib/python3.11/site-packages/adbc_driver_manager/_lib.pyx:227\u001b[0m, in \u001b[0;36madbc_driver_manager._lib.check_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: INVALID_ARGUMENT: [libpq] Failed to create table: ERROR:  relation \"sandbox.cars_output\" already exists\n\nQuery was: CREATE TABLE \"public\" . \"sandbox.cars_output\" (\"brand\" TEXT, \"model\" TEXT, \"year\" BIGINT). SQLSTATE: 42P07"
     ]
    }
   ],
   "source": [
    "df.write_database(table_name=\"sandbox.cars_output\", connection=uri, engine=\"adbc\", if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_database(table_name=\"sandbox.cars_output\", connection=con_string, engine=\"sqlalchemy\", if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>brand</th><th>model</th><th>year</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Volvo&quot;</td><td>&quot;p1800&quot;</td><td>1968</td></tr><tr><td>&quot;BMW&quot;</td><td>&quot;M1&quot;</td><td>1978</td></tr><tr><td>&quot;Toyota&quot;</td><td>&quot;Celica&quot;</td><td>1975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬────────┬──────┐\n",
       "│ brand  ┆ model  ┆ year │\n",
       "│ ---    ┆ ---    ┆ ---  │\n",
       "│ str    ┆ str    ┆ i64  │\n",
       "╞════════╪════════╪══════╡\n",
       "│ Volvo  ┆ p1800  ┆ 1968 │\n",
       "│ BMW    ┆ M1     ┆ 1978 │\n",
       "│ Toyota ┆ Celica ┆ 1975 │\n",
       "└────────┴────────┴──────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_database_uri('select * from sandbox.cars_output', uri, engine='adbc')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
